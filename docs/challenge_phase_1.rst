**********************************
Instructions for Challenge Phase 1
**********************************

.. todo:: This documentation is just a first draft, needs to be cleaned up.


Gym Environment
===============

There is a basic Gym environment implemented in ``cube_env.py``.  This can be
used by participants either as is or as a base for a custom environment.

Participants may change the reward function for training, however, the
evaluation will happen with the reward function as it is implemented in the
given environment.

A simple demo on how to use this environment with a custom policy is shown in
``demo_random_policy.py``.


Evaluation
==========

There is a script ``demo_evaluate_random_policy.py`` (TODO rename file) which
serves as an example evaluation script and can be used by participants as a
base for their own evaluation script.

Every participant needs to provide such an evaluation script.  The evaluation
script needs to fulfil the following requirements:

- Take three arguments
  1. Difficulty level (int)
  2. Initial pose of the object (JSON string)
  3. Goal pose for the object (JSON string)
- Run the simulation and run it for the number of steps defined in
  ``move_cube.episode_length``.
- After the last step, store the action log to a file called "action_log.json".
  Assuming the given ``CubeEnv`` environment is used, this can be done with the
  following line::

      env.platform.store_action_log("action_log.json")


Evaluation of Final Submission
------------------------------

For the submission, this evaluation script must be named ``run`` (without
extension) and be located in the root directory of the repository.

It will be executed through the script ``simulation_runscript.py`` (see
``--help`` for more information).

We will run submissions in the Singularity container for the evaluation.  While
it is possible to run everything without Singularity, participants are advised
to test the execution through the provided container to ensure everything works
as expected.  In case third-party dependencies are used that are not already
available in the provided container, a custom container needs to be created and
to be sent to us along with the code.

.. todo:: Add instructions how to run in Singularity and how to extend image


Replay Of Action Log
--------------------

For the evaluation of the final submission, we will replay the action log which
is generated by the evaluation script (see above).  In an isolated simulation,
without any modifications of the user, the object is initialized to the same
pose and the logged actions are applied on the robot one by one.  The actual
reward used for comparison to other participants is computed during this
replay.

The replay serves two purposes:
- Ensure that the correct reward function is used for the evaluation
  (participants may modify the reward in their environment for training).
- Prevent cheating.  In their evaluation script, participants could in theory
  access the simulation and modify the state to their favour (e.g. simply reset
  the cube state to the goal pose).  The replay is done in the original
  Singularity container and no code of the participants is executed here, so no
  cheating is possible.

The code for the replay is found in ``replay_action_log.py``.  Participants
should ensure that the replay of their action logs result in the same final
object pose as they reach in their evaluation script.  This should be the case
if the robot is only controlled through the provided interface and no direct
changes to the simulation environment are done (like changing properties of the
simulated objects).
